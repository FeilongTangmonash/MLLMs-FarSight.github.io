<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Feilong Tang*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Chengzhi Liu*</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="">Zhongxing Xu*</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Ming Hu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Zile Huang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Haochen Xue</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Ziyang Chen</a><sup>3</sup>
            </span>
            <span class="author-block">
              <a href="">Zelin Peng</a><sup>4</sup>
            </span>
            <span class="author-block">
              <a href="">Zhiwei Yang</a><sup>5</sup>
            </span>
            <span class="author-block">
              <a href="">Sijin Zhou</a><sup>1</sup>
            </span>
                <span class="author-block">
              <a href=""> Wenxue Li</a><sup>1</sup>
            </span>
                <span class="author-block">
              <a href="">Yulong Li</a><sup>2</sup>
            </span>
                <span class="author-block">
              <a href="">Wenxuan Song</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Shiyan Su</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Wei Feng</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Jionglong Su</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="">Minquan Lin</a><sup>6</sup>
            </span>
            <span class="author-block">
              <a href="">Yifan Peng</a><sup>7</sup>
            </span>
            <span class="author-block">
              <a href="">Xuelian Cheng</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="">Imran Razzak†</a><sup>8</sup>
            </span>
              <span class="author-block">
              <a href="">Zongyuan Ge†</a><sup>1</sup>
            </span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Monash University,</span>
            <span class="author-block"><sup>2</sup>University of Liverpool</span>
            <span class="author-block"><sup>2</sup>Northwestern Polytechnical University</span>
            <span class="author-block"><sup>2</sup>Shanghai Jiaotong University</span>
            <span class="author-block"><sup>2</sup>Fudan University</span>
            <span class="author-block"><sup>2</sup>University of Minnesota</span>
            <span class="author-block"><sup>2</sup>Cornell University</span>
            <span class="author-block"><sup>2</sup>University of New South Wales</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--               <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--               <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

 <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Recent advancements in multimodal large language models (MLLMs) have significantly improved performance in visual question answering. However, they often suffer from hallucinations. In this work, hallucinations are categorized into two main types: initial hallucinations and snowball hallucinations. We argue that adequate contextual information can be extracted directly from the token interaction process. Inspired by causal inference in decoding strategy, we propose to leverage causal masks to establish information propagation between multimodal tokens. The hypothesis is that insufficient interaction between those tokens may lead the model to rely on outlier tokens, overlooking dense and rich contextual cues. Therefore, we propose to intervene in the propagation process by tackling outlier tokens to enhance in-context inference. With this goal, we present FarSight, a versatile plug-and-play decoding strategy to reduce attention interference from outlier tokens merely by optimizing the causal mask. The heart of our method is effective token propagation. We design an attention register structure within the upper triangular matrix of the causal mask, dynamically allocating attention capture attention diverted to outlier tokens. Moreover, a positional awareness encoding method with a diminishing masking rate is proposed, allowing the model to attend to further preceding tokens, especially for video sequence tasks. With extensive experiments, FarSight demonstrates significant hallucination-mitigating performance across different MLLMs on both image and video benchmarks, proving its effectiveness.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered" style="margin-top: 2rem;">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Methodology</h2>
      </div>
      </div>


   <div class="columns is-centered has-text-centered" style="margin-top: 0rem;">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Visualization</h2>
  </div>
</div>

<section class="section" style="margin-top: -2.6rem;">
  <figure class="image is-centered" style="width: 80%; margin: 0 auto 1rem; text-align: center;">
    <img 
      src="./static/table1.png" 
      alt="image" 
      style="width: 100%; height: auto;" 
      loading="lazy"
    />
    <figcaption style="text-align: center;">
      Table 1. Accuracy of MLLMs under instruction following setting. All of the MLLMs struggle to respond with safety awareness under unsafe situations and perform even worse in Embodied Task.
    </figcaption>
  </figure>
</section>

<section class="section" id="BibTeX">
  <div class="container content" style="max-width: 800px; margin: 0 auto;">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      
    </code></pre>
  </div>
</section>

</body>
</html>
